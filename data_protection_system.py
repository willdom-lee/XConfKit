#!/usr/bin/env python3
"""
æ•°æ®ä¿æŠ¤ç³»ç»Ÿ - é˜²æ­¢æ•°æ®ä¸¢å¤±å’Œå¼‚å¸¸é‡æ„
"""

import sqlite3
import os
import shutil
import json
from datetime import datetime
import hashlib
from pathlib import Path

class DataProtectionSystem:
    def __init__(self, db_path="data/xconfkit.db"):
        self.db_path = db_path
        self.backup_dir = "data/backups"
        self.protection_dir = "data/protection"
        self.metadata_file = f"{self.protection_dir}/metadata.json"
        
        # ç¡®ä¿ä¿æŠ¤ç›®å½•å­˜åœ¨
        os.makedirs(self.protection_dir, exist_ok=True)
    
    def create_data_snapshot(self, snapshot_name=None):
        """åˆ›å»ºæ•°æ®å¿«ç…§"""
        if not os.path.exists(self.db_path):
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return False
        
        if snapshot_name is None:
            snapshot_name = f"snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        snapshot_dir = f"{self.protection_dir}/{snapshot_name}"
        os.makedirs(snapshot_dir, exist_ok=True)
        
        try:
            # 1. å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
            snapshot_db = f"{snapshot_dir}/xconfkit.db"
            shutil.copy2(self.db_path, snapshot_db)
            
            # 2. åˆ›å»ºæ•°æ®æ‘˜è¦
            data_summary = self._get_data_summary()
            
            # 3. ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "snapshot_name": snapshot_name,
                "created_at": datetime.now().isoformat(),
                "data_summary": data_summary,
                "file_size": os.path.getsize(self.db_path),
                "file_hash": self._calculate_file_hash(self.db_path)
            }
            
            with open(f"{snapshot_dir}/metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # 4. æ›´æ–°ä¸»å…ƒæ•°æ®æ–‡ä»¶
            self._update_main_metadata(snapshot_name, metadata)
            
            print(f"âœ… æ•°æ®å¿«ç…§åˆ›å»ºæˆåŠŸ: {snapshot_name}")
            print(f"   ğŸ“Š æ•°æ®æ‘˜è¦: {data_summary}")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºæ•°æ®å¿«ç…§å¤±è´¥: {e}")
            return False
    
    def restore_from_snapshot(self, snapshot_name):
        """ä»å¿«ç…§æ¢å¤æ•°æ®"""
        snapshot_dir = f"{self.protection_dir}/{snapshot_name}"
        snapshot_db = f"{snapshot_dir}/xconfkit.db"
        
        if not os.path.exists(snapshot_db):
            print(f"âŒ å¿«ç…§ä¸å­˜åœ¨: {snapshot_name}")
            return False
        
        try:
            # 1. åˆ›å»ºå½“å‰æ•°æ®çš„å¤‡ä»½
            current_backup = f"data/xconfkit_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            if os.path.exists(self.db_path):
                shutil.copy2(self.db_path, current_backup)
                print(f"ğŸ“¦ å½“å‰æ•°æ®å·²å¤‡ä»½åˆ°: {current_backup}")
            
            # 2. æ¢å¤å¿«ç…§æ•°æ®
            shutil.copy2(snapshot_db, self.db_path)
            
            # 3. éªŒè¯æ¢å¤ç»“æœ
            restored_summary = self._get_data_summary()
            with open(f"{snapshot_dir}/metadata.json", 'r', encoding='utf-8') as f:
                original_metadata = json.load(f)
            
            if restored_summary == original_metadata["data_summary"]:
                print(f"âœ… æ•°æ®æ¢å¤æˆåŠŸ: {snapshot_name}")
                print(f"   ğŸ“Š æ¢å¤çš„æ•°æ®: {restored_summary}")
                return True
            else:
                print(f"âŒ æ•°æ®æ¢å¤éªŒè¯å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ æ¢å¤æ•°æ®å¤±è´¥: {e}")
            return False
    
    def list_snapshots(self):
        """åˆ—å‡ºæ‰€æœ‰å¿«ç…§"""
        if not os.path.exists(self.protection_dir):
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°ä¿æŠ¤ç›®å½•")
            return []
        
        snapshots = []
        for item in os.listdir(self.protection_dir):
            item_path = f"{self.protection_dir}/{item}"
            if os.path.isdir(item_path) and os.path.exists(f"{item_path}/metadata.json"):
                try:
                    with open(f"{item_path}/metadata.json", 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    snapshots.append(metadata)
                except:
                    continue
        
        return sorted(snapshots, key=lambda x: x["created_at"], reverse=True)
    
    def validate_data_integrity(self):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        if not os.path.exists(self.db_path):
            print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
            return False
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥å…³é”®è¡¨æ˜¯å¦å­˜åœ¨
            required_tables = ['devices', 'backups', 'strategies', 'configs', 'ai_configs', 'analysis_prompts']
            missing_tables = []
            
            for table in required_tables:
                cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table}'")
                if not cursor.fetchone():
                    missing_tables.append(table)
            
            if missing_tables:
                print(f"âŒ ç¼ºå°‘å…³é”®è¡¨: {missing_tables}")
                return False
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            data_summary = self._get_data_summary()
            print(f"âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
            print(f"   ğŸ“Š å½“å‰æ•°æ®: {data_summary}")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
        finally:
            if conn:
                conn.close()
    
    def auto_backup_before_changes(self):
        """åœ¨å˜æ›´å‰è‡ªåŠ¨å¤‡ä»½"""
        print("ğŸ”„ æ‰§è¡Œå˜æ›´å‰è‡ªåŠ¨å¤‡ä»½...")
        return self.create_data_snapshot("auto_backup_before_changes")
    
    def _get_data_summary(self):
        """è·å–æ•°æ®æ‘˜è¦"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            summary = {}
            tables = ['devices', 'backups', 'strategies', 'configs', 'ai_configs', 'analysis_prompts']
            
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                summary[table] = count
            
            return summary
            
        except Exception as e:
            return {"error": str(e)}
        finally:
            if conn:
                conn.close()
    
    def _calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def _update_main_metadata(self, snapshot_name, metadata):
        """æ›´æ–°ä¸»å…ƒæ•°æ®æ–‡ä»¶"""
        main_metadata = {}
        if os.path.exists(self.metadata_file):
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    main_metadata = json.load(f)
            except:
                pass
        
        if "snapshots" not in main_metadata:
            main_metadata["snapshots"] = []
        
        # æ·»åŠ æ–°å¿«ç…§
        main_metadata["snapshots"].append({
            "name": snapshot_name,
            "created_at": metadata["created_at"],
            "data_summary": metadata["data_summary"]
        })
        
        # ä¿æŒæœ€å¤š10ä¸ªå¿«ç…§
        if len(main_metadata["snapshots"]) > 10:
            main_metadata["snapshots"] = main_metadata["snapshots"][-10:]
        
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(main_metadata, f, indent=2, ensure_ascii=False)

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®ä¿æŠ¤ç³»ç»Ÿ"""
    dps = DataProtectionSystem()
    
    print("ğŸ›¡ï¸  XConfKit æ•°æ®ä¿æŠ¤ç³»ç»Ÿ")
    print("=" * 50)
    
    # 1. éªŒè¯æ•°æ®å®Œæ•´æ€§
    print("\n1. éªŒè¯æ•°æ®å®Œæ•´æ€§:")
    dps.validate_data_integrity()
    
    # 2. åˆ›å»ºå½“å‰æ•°æ®å¿«ç…§
    print("\n2. åˆ›å»ºæ•°æ®å¿«ç…§:")
    dps.create_data_snapshot("current_state")
    
    # 3. åˆ—å‡ºæ‰€æœ‰å¿«ç…§
    print("\n3. åˆ—å‡ºæ‰€æœ‰å¿«ç…§:")
    snapshots = dps.list_snapshots()
    for snapshot in snapshots:
        print(f"   ğŸ“¸ {snapshot['snapshot_name']} - {snapshot['created_at']}")
        print(f"      ğŸ“Š {snapshot['data_summary']}")
    
    print("\nâœ… æ•°æ®ä¿æŠ¤ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("- åœ¨é‡è¦æ“ä½œå‰è°ƒç”¨ auto_backup_before_changes()")
    print("- å®šæœŸåˆ›å»ºæ•°æ®å¿«ç…§")
    print("- ä½¿ç”¨ restore_from_snapshot() æ¢å¤æ•°æ®")

if __name__ == "__main__":
    main()
